{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3XCqd9nmmini"
   },
   "outputs": [],
   "source": [
    "# !pip install pyvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OK0jFWTIvj7f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "import re\n",
    "from pyvi import ViTokenizer\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, LSTM, Input\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1310,
     "status": "ok",
     "timestamp": 1620959987823,
     "user": {
      "displayName": "Nguyễn Hoàng Minh Thư",
      "photoUrl": "https://lh3.googleusercontent.com/-sQOkixFpKwk/AAAAAAAAAAI/AAAAAAAAAAw/hZug3omYpwE/s64/photo.jpg",
      "userId": "01886041070010615565"
     },
     "user_tz": -420
    },
    "id": "nsRvjEMqvj7p",
    "outputId": "43faead3-fdbd-4bc9-a889-a62062dfdc8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bạn bè.txt', 'các câu hỏi phức tạp.txt', 'du lịch.txt', 'gia đình.txt', 'giải trí.txt', 'học tập.txt', 'nghề nghiệp.txt', 'nghỉ lễ.txt', 'người yêu.txt', 'robot.txt', 'shoping.txt', 'sở thích.txt', 'tdtu.txt', 'thông tin cá nhân.txt', 'trò chuyện về đi ăn.txt', 'tán gẫu.txt', 'đất nước.txt', 'địa chỉ.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dir = 'data/chatbot'\n",
    "filenames = os.listdir(dir)\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3791,
     "status": "ok",
     "timestamp": 1620959994021,
     "user": {
      "displayName": "Nguyễn Hoàng Minh Thư",
      "photoUrl": "https://lh3.googleusercontent.com/-sQOkixFpKwk/AAAAAAAAAAI/AAAAAAAAAAw/hZug3omYpwE/s64/photo.jpg",
      "userId": "01886041070010615565"
     },
     "user_tz": -420
    },
    "id": "l9JSiGuhvj7r",
    "outputId": "01601e03-a710-471c-e77d-d479401fe0bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of QA pairs: 5855\n"
     ]
    }
   ],
   "source": [
    "Q = []\n",
    "A = []\n",
    "for i in filenames:\n",
    "    with open(dir+'/'+i, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            a =  line.split('__eou__')\n",
    "            Q.append(a[0])\n",
    "            A.append(a[1])\n",
    "print('Number of QA pairs:', len(Q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Cain1lRNvj7r"
   },
   "outputs": [],
   "source": [
    "# word segment, clean punctuation of a sentence\n",
    "def normalize(sent):\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    return ViTokenizer.tokenize(regex.sub('', sent.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QtxnPb0Cvj7s"
   },
   "outputs": [],
   "source": [
    "stop_words = np.loadtxt('data/vietnamese-stopwords-dash.txt', dtype=str)\n",
    "def clean_stop_words(sent):\n",
    "    clean_sent = ''\n",
    "    for w in sent.split():\n",
    "        if w not in stop_words:\n",
    "            clean_sent += w + ' '\n",
    "    return clean_sent.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "JatffY9Nvj7t"
   },
   "outputs": [],
   "source": [
    "# normalize questions and answers\n",
    "questions = []\n",
    "answers = []\n",
    "for i in range(len(Q)):\n",
    "    questions.append(clean_stop_words(normalize(Q[i]))) # only clean stop words from questions\n",
    "    answers.append(normalize(A[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "x7zf0U6Nvj7u"
   },
   "outputs": [],
   "source": [
    "# start and end of string token to each answer\n",
    "for i in range(len(answers)):\n",
    "    answers[i] = '<start> ' + answers[i] + ' <end>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 805,
     "status": "ok",
     "timestamp": 1620960115722,
     "user": {
      "displayName": "Nguyễn Hoàng Minh Thư",
      "photoUrl": "https://lh3.googleusercontent.com/-sQOkixFpKwk/AAAAAAAAAAI/AAAAAAAAAAw/hZug3omYpwE/s64/photo.jpg",
      "userId": "01886041070010615565"
     },
     "user_tz": -420
    },
    "id": "L90MakM0vj7y",
    "outputId": "08a6011f-e8c7-4bc2-988c-c31bc84497c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB SIZE: 4927\n"
     ]
    }
   ],
   "source": [
    "# count each token appearing time \n",
    "tokenizer = Tokenizer(filters='')\n",
    "tokenizer.fit_on_texts(questions + answers)\n",
    "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
    "print('VOCAB SIZE: {}'.format(VOCAB_SIZE))\n",
    "vocab = list(tokenizer.word_index.keys()) # list of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 790,
     "status": "ok",
     "timestamp": 1620960475028,
     "user": {
      "displayName": "Nguyễn Hoàng Minh Thư",
      "photoUrl": "https://lh3.googleusercontent.com/-sQOkixFpKwk/AAAAAAAAAAI/AAAAAAAAAAw/hZug3omYpwE/s64/photo.jpg",
      "userId": "01886041070010615565"
     },
     "user_tz": -420
    },
    "id": "WAl_Wm8gwJnG",
    "outputId": "6ebb3cec-23ee-4405-b204-5eda960340ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train data after cleaning: 5377\n"
     ]
    }
   ],
   "source": [
    "# due to stop words cleaning, there are empty questions\n",
    "# => remove them from train data\n",
    "tokenized_questions = tokenizer.texts_to_sequences(questions)\n",
    "tokenized_answers = tokenizer.texts_to_sequences(answers)\n",
    "\n",
    "indices = []\n",
    "for i in range(len(tokenized_questions)):\n",
    "    if len(tokenized_questions[i])==0:\n",
    "        indices.append(i)\n",
    "tokenized_questions = np.delete(np.array(tokenized_questions, dtype=object), indices)\n",
    "tokenized_answers = np.delete(np.array(tokenized_answers, dtype=object), indices)\n",
    "print('Number of train data after cleaning:', len(tokenized_questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 842,
     "status": "ok",
     "timestamp": 1620960478343,
     "user": {
      "displayName": "Nguyễn Hoàng Minh Thư",
      "photoUrl": "https://lh3.googleusercontent.com/-sQOkixFpKwk/AAAAAAAAAAI/AAAAAAAAAAw/hZug3omYpwE/s64/photo.jpg",
      "userId": "01886041070010615565"
     },
     "user_tz": -420
    },
    "id": "d1UdhpNUvj70",
    "outputId": "1fc607f3-dc03-45d4-ce4a-48259e7151a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder input data shape: (5377, 18)\n",
      "Max length of encoder input data: 18\n"
     ]
    }
   ],
   "source": [
    "maxlen_questions = max([len(x) for x in tokenized_questions])\n",
    "padded_questions = pad_sequences(tokenized_questions, maxlen=maxlen_questions, padding='post')\n",
    "encoder_input_data = np.array( padded_questions )\n",
    "print('Encoder input data shape:', encoder_input_data.shape)\n",
    "print('Max length of encoder input data:', maxlen_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 692,
     "status": "ok",
     "timestamp": 1620960481466,
     "user": {
      "displayName": "Nguyễn Hoàng Minh Thư",
      "photoUrl": "https://lh3.googleusercontent.com/-sQOkixFpKwk/AAAAAAAAAAI/AAAAAAAAAAw/hZug3omYpwE/s64/photo.jpg",
      "userId": "01886041070010615565"
     },
     "user_tz": -420
    },
    "id": "Y-g2Z_ibvj71",
    "outputId": "e6569561-a5ba-4490-beab-6b165bec28e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder input data shape: (5377, 113)\n",
      "Max length of encoder input data: 113\n"
     ]
    }
   ],
   "source": [
    "maxlen_answers = max([len(x) for x in tokenized_answers])\n",
    "padded_answers = pad_sequences(tokenized_answers, maxlen=maxlen_answers, padding='post')\n",
    "decoder_input_data = np.array(padded_answers)\n",
    "print('Encoder input data shape:', decoder_input_data.shape)\n",
    "print('Max length of encoder input data:', maxlen_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3165,
     "status": "ok",
     "timestamp": 1620960513658,
     "user": {
      "displayName": "Nguyễn Hoàng Minh Thư",
      "photoUrl": "https://lh3.googleusercontent.com/-sQOkixFpKwk/AAAAAAAAAAI/AAAAAAAAAAw/hZug3omYpwE/s64/photo.jpg",
      "userId": "01886041070010615565"
     },
     "user_tz": -420
    },
    "id": "fEpd4v7Mvj73",
    "outputId": "58b454cf-d703-4ea8-cef1-41495f2894ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder ouput data shape: (5377, 113, 4927)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(tokenized_answers)):\n",
    "    tokenized_answers[i] = tokenized_answers[i][1:]\n",
    "padded_answers = pad_sequences(tokenized_answers, maxlen=maxlen_answers, padding='post')\n",
    "one_hot_answers = to_categorical(padded_answers, VOCAB_SIZE, dtype='uint8')\n",
    "decoder_output_data = np.array(one_hot_answers)\n",
    "print('Decoder ouput data shape:', decoder_output_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "slipHGSXvj73"
   },
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None,))\n",
    "encoder_embedding = Embedding(VOCAB_SIZE, 200, mask_zero=True) (encoder_inputs)\n",
    "encoder_outputs, state_h, state_c = LSTM(200, return_state=True) (encoder_embedding)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UYaJaLp7vj74"
   },
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None,))\n",
    "decoder_embedding = Embedding(VOCAB_SIZE, 200, mask_zero=True) (decoder_inputs)\n",
    "decoder_lstm = LSTM(200, return_state=True, return_sequences=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_dense = Dense(VOCAB_SIZE, activation='softmax') \n",
    "output = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 791,
     "status": "ok",
     "timestamp": 1620969058169,
     "user": {
      "displayName": "Mạc Thuận Đạt",
      "photoUrl": "",
      "userId": "04053425703813548381"
     },
     "user_tz": -420
    },
    "id": "zpxqS0CQvj74",
    "outputId": "c7c6e53e-f04b-44c4-a738-80897f7e8cb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 200)    985400      input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 200)    985400      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 200), (None, 320800      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 200),  320800      embedding_3[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 4927)   990327      lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,602,727\n",
      "Trainable params: 3,602,727\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 384193,
     "status": "ok",
     "timestamp": 1620972269378,
     "user": {
      "displayName": "Mạc Thuận Đạt",
      "photoUrl": "",
      "userId": "04053425703813548381"
     },
     "user_tz": -420
    },
    "id": "Gi27qYt8vj74",
    "outputId": "03dd453c-8dec-4c03-930a-dfeabf65390c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "169/169 [==============================] - 157s 930ms/step - loss: 0.3397 - accuracy: 0.3035\n",
      "Epoch 2/5\n",
      "169/169 [==============================] - 158s 938ms/step - loss: 0.3265 - accuracy: 0.3147\n",
      "Epoch 3/5\n",
      "169/169 [==============================] - 159s 940ms/step - loss: 0.3138 - accuracy: 0.3260\n",
      "Epoch 4/5\n",
      "169/169 [==============================] - 158s 937ms/step - loss: 0.3019 - accuracy: 0.3367\n",
      "Epoch 5/5\n",
      "169/169 [==============================] - 159s 944ms/step - loss: 0.2910 - accuracy: 0.3497\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3ddb710350>"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_input_data , decoder_input_data], decoder_output_data, epochs=5) # epochs>=10, run 2 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QaESKXhfvj75"
   },
   "outputs": [],
   "source": [
    "def make_inference_models():\n",
    "    encoder_model = Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "    decoder_state_input_h = Input(shape=(200,))\n",
    "    decoder_state_input_c = Input(shape=(200,))\n",
    "    \n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    \n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(decoder_embedding, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "    \n",
    "    return encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iZJwkGzpvj75"
   },
   "outputs": [],
   "source": [
    "def format_question(sent:str):\n",
    "    words = clean_stop_words(normalize(sent)).split()\n",
    "    tokens_list = [tokenizer.word_index[w] for w in words]\n",
    "    return pad_sequences([tokens_list], maxlen=maxlen_questions, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uulGjkja_OYb"
   },
   "outputs": [],
   "source": [
    "enc_model, dec_model = make_inference_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v_4uY17Uvj77"
   },
   "outputs": [],
   "source": [
    "def ask(question):\n",
    "    states_values = enc_model.predict(format_question(question))\n",
    "    empty_target_seq = np.zeros((1, 1))\n",
    "    empty_target_seq[0, 0] = tokenizer.word_index['<start>']\n",
    "    stop_condition = False\n",
    "    decoded_translation = ''\n",
    "    while not stop_condition:\n",
    "        dec_outputs, h, c = dec_model.predict([empty_target_seq] + states_values)\n",
    "        sampled_word_index = np.argmax(dec_outputs[0, -1, :])\n",
    "        sampled_word = None\n",
    "        for word, index in tokenizer.word_index.items() :\n",
    "            if sampled_word_index == index:\n",
    "                decoded_translation += '{} '.format(word)\n",
    "                sampled_word = word\n",
    "        \n",
    "        if sampled_word == '<end>' or len(decoded_translation.split()) > maxlen_answers:\n",
    "            stop_condition = True\n",
    "            \n",
    "        empty_target_seq = np.zeros((1, 1))  \n",
    "        empty_target_seq[0, 0] = sampled_word_index\n",
    "        states_values = [h, c]\n",
    "    return decoded_translation[0].upper() + decoded_translation[1:].replace('_', ' ').replace('<end>', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2557,
     "status": "ok",
     "timestamp": 1620982629904,
     "user": {
      "displayName": "Mạc Thuận Đạt",
      "photoUrl": "",
      "userId": "04053425703813548381"
     },
     "user_tz": -420
    },
    "id": "wHf4mNuAvj77",
    "outputId": "1f6c0216-b59f-4bd4-d7eb-90cfada0cf09",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mình sinh năm 2001  \n",
      "Mình chưa có người yêu  \n",
      "Mình nghĩ là được  \n",
      "Quê mình ở tiền giang  \n",
      "Mình thích chơi game  \n",
      "Mình đi xem phim  \n",
      "Mình thích chơi game  \n"
     ]
    }
   ],
   "source": [
    "print(ask('Bạn sinh năm bao nhiêu?'))\n",
    "print(ask('Có người yêu chưa?'))\n",
    "print(ask('Shop tư vấn cho mình một số mẫu giày thích hợp để đi chơi được không?'))\n",
    "print(ask('Quê bạn ở đâu?'))\n",
    "print(ask('Bạn thường làm gì trong thời gian rảnh?'))\n",
    "print(ask('Bạn có muốn đi xem phim vào cuối tuần này hay không?'))\n",
    "print(ask('Bạn thích môn thể thao gì?'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "generative.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
